{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1341d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import dsacstar\n",
    "import os\n",
    "\n",
    "from network import Network\n",
    "import datasets\n",
    "from utils import tr, reverse_tr\n",
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981d0ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:07<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:10<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:05<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:05<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting depths, this may take a while...\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.SevenScenesDataset(f'/mundus/mrahman527/projects/homography-loss-function/datasets/7-Scenes/fire', 0.025, 0.975)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9db554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ABC(w_t_c, c_R_w, w_t_chat, chat_R_w, c_n, eye):\n",
    "    \"\"\"\n",
    "    Computes A, B, and C matrix given estimated and ground truth poses\n",
    "    and normal vector n.\n",
    "    `w_t_c` and `w_t_chat` must have shape (batch_size, 3, 1).\n",
    "    `c_R_w` and `chat_R_w` must have shape (batch_size, 3, 3).\n",
    "    `n` must have shape (3, 1).\n",
    "    `eye` is the (3, 3) identity matrix on the proper device.\n",
    "    \"\"\"\n",
    "    chat_t_c = chat_R_w @ (w_t_c - w_t_chat)\n",
    "#     print(f\"in abc chatRW={chat_R_w.shape} and transpose={c_R_w.transpose(1,2).shape}\")\n",
    "    chat_R_c = chat_R_w @ c_R_w.transpose(1, 2)\n",
    "\n",
    "    A = eye - chat_R_c\n",
    "    C = c_n @ chat_t_c.transpose(1, 2)\n",
    "    B = C @ A\n",
    "    A = A @ A.transpose(1, 2)\n",
    "    B = B + B.transpose(1, 2)\n",
    "    C = C @ C.transpose(1, 2)\n",
    "\n",
    "    return A, B, C\n",
    "\n",
    "\n",
    "class LocalHomographyLoss(torch.nn.Module):\n",
    "    def __init__(self, device='cpu'):\n",
    "        super().__init__()\n",
    "\n",
    "        # `c_n` is the normal vector of the plane inducing the homographies in the ground-truth camera frame\n",
    "        self.c_n = torch.tensor([0, 0, -1], dtype=torch.float32, device=device).view(3, 1)\n",
    "\n",
    "        # `eye` is the (3, 3) identity matrix\n",
    "        self.eye = torch.eye(3, device=device)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        A, B, C = compute_ABC(batch['w_t_c'], batch['c_R_w'], batch['w_t_chat'], batch['chat_R_w'], self.c_n, self.eye)\n",
    "\n",
    "        xmin = batch['xmin'].view(-1, 1, 1)\n",
    "        xmax = batch['xmax'].view(-1, 1, 1)\n",
    "        B_weight = torch.log(xmax / xmin) / (xmax - xmin)\n",
    "        C_weight = xmin * xmax\n",
    "\n",
    "        error = A + B * B_weight + C / C_weight\n",
    "        error = error.diagonal(dim1=1, dim2=2).sum(dim=1).mean()\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bb135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = datasets.RelocDataset(dataset.train_data)\n",
    "test_dataset = datasets.RelocDataset(dataset.test_data)\n",
    "\n",
    "trainset_loader = torch.utils.data.DataLoader(train_dataset, shuffle=False, num_workers=6, batch_size=1)\n",
    "testset_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, num_workers=6, batch_size=1)\n",
    "\n",
    "# load network\n",
    "network = Network(torch.zeros((3)), False)\n",
    "with_init=False\n",
    "network = network.cuda()\n",
    "network.train()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(),lr=0.000001)\n",
    "iteration = 2\n",
    "\n",
    "if with_init:\n",
    "    writer_folder = 'with_init'\n",
    "else:\n",
    "    writer_folder = 'without_init'\n",
    "    \n",
    "    \n",
    "writer = SummaryWriter(os.path.join('logs',os.path.basename(os.path.normpath('7-Scenes')),'fire',writer_folder))\n",
    "\n",
    "\n",
    "if with_init:\n",
    "        checkpoint_folder = f'our_checkpoints/{opt.dataset_name}/{opt.scene_name}_with_init'\n",
    "        os.mkdir(checkpoint_folder)\n",
    "else:\n",
    "    checkpoint_folder = f\"our_checkpoints/{'7-Scenes'}/{'fire'}_without_init\"\n",
    "    if os.path.isdir(checkpoint_folder):\n",
    "        checkpoint_folder = checkpoint_folder+'_1'\n",
    "\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa41bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac32bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "\n",
      "loss: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(network = network,trainset_loader=trainset_loader,testset_laoder=testset_loader,optimizer=optimizer, iteration=iteration, with_init=with_init, writer=writer,checkpoint_folder=checkpoint_folder):\n",
    "    \n",
    "    for epoch in range(iteration):\n",
    "        network.train()\n",
    "        print(f'epoch:{epoch}\\n')\n",
    "        \n",
    "        running_loss = 0\n",
    "        it = 0\n",
    "        for data in trainset_loader:\n",
    "            break\n",
    "            it+=1\n",
    "            with torch.no_grad():\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            focal_length = data['K'][0][0][0]\n",
    "            file = data['image_file']\n",
    "            image = data['image'].cuda()\n",
    "#             start_time = time.time()\n",
    "            wtc, crw = data['w_t_c'], data['c_R_w']\n",
    "            \n",
    "            # predict scene coordinates and neural guidance\n",
    "            scene_coordinates = network(image)\n",
    "            scene_coordinates_gradients = torch.zeros(scene_coordinates.size())\n",
    "            gt_pose = reverse_tr(crw, wtc)[0]\n",
    "            # print(f\"shape pose={gt_pose.shape}\")\n",
    "            # print(f\"xmin = {data['xmin']} shape {data['xmin'].shape}\")\n",
    "            # print(f\"xmax = {data['xmax']} shape {data['xmax'].shape}\")\n",
    "\n",
    "            # pose from RGB\n",
    "            loss = dsacstar.backward_rgb(\n",
    "                scene_coordinates.cpu(),\n",
    "                scene_coordinates_gradients,\n",
    "                gt_pose, \n",
    "                64, \n",
    "                10,\n",
    "                focal_length, \n",
    "                float(image.size(3) / 2), #principal point assumed in image center\n",
    "                float(image.size(2) / 2),\n",
    "                1.0,\n",
    "                100.0,\n",
    "                100,\n",
    "                100,\n",
    "                100,\n",
    "                network.OUTPUT_SUBSAMPLE,\n",
    "                random.randint(0,1000000), #used to initialize random number generator in cpp\n",
    "                data['xmin'].item(),\n",
    "                data['xmax'].item()\n",
    "            )\n",
    "    \n",
    "            \n",
    "            running_loss += loss\n",
    "            torch.autograd.backward((scene_coordinates),(scene_coordinates_gradients.cuda()))\n",
    "            optimizer.step()\n",
    "            if it%10==0 and it!=0:\n",
    "                writer.add_scalar('train loss',running_loss/it)\n",
    "                \n",
    "        \n",
    "        writer.add_scalar('per_epoch_training_loss',running_loss/len(trainset_loader),epoch)\n",
    "        \n",
    "\n",
    "#         if epoch%opt.save_every==0:\n",
    "#             checkpoint_path = os.path.join(checkpoint_folder,f'check_point_epoch_{epoch}.pt')\n",
    "#             torch.save(\n",
    "#                 {\n",
    "#                     'epoch': epoch,\n",
    "#                     'model_state_dict': network.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "\n",
    "#                 }, checkpoint_path\n",
    "#             )\n",
    "       \n",
    "        print(f\"loss: {running_loss}\")\n",
    "        criterion = LocalHomographyLoss()\n",
    "        #test\n",
    "        network.eval()\n",
    "        it = 0\n",
    "        running_test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testset_loader:\n",
    "                it+=1\n",
    "                focal_length = data['K'][0][0][0]\n",
    "                file = data['image_file']\n",
    "                image = data['image'].cuda()\n",
    "                wtc, crw = data['w_t_c'], data['c_R_w']\n",
    "\n",
    "                # predict scene coordinates and neural guidance\n",
    "                scene_coordinates = network(image)\n",
    "                gt_pose = reverse_tr(crw, wtc)[0]\n",
    "                out_pose = torch.zeros((4,4))\n",
    "                print('here')\n",
    "                dsacstar.forward_rgb(\n",
    "                    scene_coordinates,\n",
    "                    out_pose,\n",
    "                    64,\n",
    "                    10,\n",
    "                    focal_length,\n",
    "                    float(image.size(3)/2),\n",
    "                    float(image.size(2)/2),\n",
    "                    100,\n",
    "                    100,\n",
    "                    network.OUTPUT_SUBSAMPLE\n",
    "                )\n",
    "                print('here 2')\n",
    "                \n",
    "                batch={}\n",
    "                batch['w_t_c'] = data['w_t_c']\n",
    "                batch['c_R_w'] = data['c_R_w']\n",
    "                \n",
    "                batch['w_t_chat'],batch['chat_R_w'] = tr(out_pose)\n",
    "                batch['w_t_chat'] = batch['w_t_chat'].unsqueeze(0)\n",
    "                batch['chat_R_w'] = batch['chat_R_w'].unsqueeze(0)\n",
    "                batch['xmin'] = data['xmin']\n",
    "                batch['xmax'] = data['xmax']\n",
    "                \n",
    "                print('here 3')\n",
    "                loss = criterion(batch)\n",
    "                running_test_loss+=loss.item()\n",
    "                print(running_test_loss)\n",
    "\n",
    "                \n",
    "    \n",
    "\n",
    "train(network = network, optimizer=optimizer, iteration=iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d5d40a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  8 17:18:52 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090         On | 00000000:1B:00.0 Off |                  N/A |\r\n",
      "|  0%   40C    P8               25W / 350W|   2781MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   3226735      C   ...miniconda3/envs/dsacstar/bin/python     2778MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
