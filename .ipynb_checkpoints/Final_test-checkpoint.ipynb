{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aba7ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import dsacstar\n",
    "import os\n",
    "\n",
    "from network import Network\n",
    "import datasets\n",
    "from utils import tr, reverse_tr\n",
    "import pickle\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f17add27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:18<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:18<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:14<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading seq-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:13<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting depths, this may take a while...\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.SevenScenesDataset(f'/mundus/mrahman527/projects/homography-loss-function/datasets/7-Scenes/fire', 0.025, 0.975)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e91cb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = datasets.RelocDataset(dataset.train_data)\n",
    "test_dataset = datasets.RelocDataset(dataset.test_data)\n",
    "\n",
    "trainset_loader = torch.utils.data.DataLoader(train_dataset, shuffle=False, num_workers=6, batch_size=1)\n",
    "testset_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, num_workers=6, batch_size=1)\n",
    "\n",
    "# load network\n",
    "network = Network(torch.zeros((3)), False)\n",
    "with_init=False\n",
    "network = network.cuda()\n",
    "network.train()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(),lr=0.000001)\n",
    "iteration = 2\n",
    "\n",
    "if with_init:\n",
    "    writer_folder = 'with_init'\n",
    "else:\n",
    "    writer_folder = 'without_init'\n",
    "    \n",
    "    \n",
    "writer = SummaryWriter(os.path.join('logs',os.path.basename(os.path.normpath('7-Scenes')),'fire',writer_folder))\n",
    "\n",
    "\n",
    "if with_init:\n",
    "        checkpoint_folder = f'our_checkpoints/{opt.dataset_name}/{opt.scene_name}_with_init'\n",
    "        os.mkdir(checkpoint_folder)\n",
    "else:\n",
    "    checkpoint_folder = f\"our_checkpoints/{'7-Scenes'}/{'fire'}_without_init\"\n",
    "    if os.path.isdir(checkpoint_folder):\n",
    "        checkpoint_folder = checkpoint_folder+'_1'\n",
    "\n",
    "    os.makedirs(checkpoint_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46799fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "535e98ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dsacstar_with_homography' has no attribute 'backward_rgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3226735/40179203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3226735/40179203.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, trainset_loader, testset_laoder, optimizer, iteration, with_init, writer, checkpoint_folder)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# pose from RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             loss = dsacstar.backward_rgb(\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mscene_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mscene_coordinates_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dsacstar_with_homography' has no attribute 'backward_rgb'"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(network = network,trainset_loader=trainset_loader,testset_laoder=testset_loader,optimizer=optimizer, iteration=iteration, with_init=with_init, writer=writer,checkpoint_folder=checkpoint_folder):\n",
    "\n",
    "    for epoch in range(iteration):\n",
    "        print(f'epoch:{epoch}\\n')\n",
    "        running_loss = 0\n",
    "        it = 0\n",
    "        for data in trainset_loader:\n",
    "            it+=1\n",
    "            with torch.no_grad():\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            focal_length = data['K'][0][0][0]\n",
    "            file = data['image_file']\n",
    "            image = data['image'].cuda()\n",
    "#             start_time = time.time()\n",
    "            wtc, crw = data['w_t_c'], data['c_R_w']\n",
    "            \n",
    "            # predict scene coordinates and neural guidance\n",
    "            scene_coordinates = network(image)\n",
    "            scene_coordinates_gradients = torch.zeros(scene_coordinates.size())\n",
    "            gt_pose = reverse_tr(crw, wtc)[0]\n",
    "            # print(f\"shape pose={gt_pose.shape}\")\n",
    "            # print(f\"xmin = {data['xmin']} shape {data['xmin'].shape}\")\n",
    "            # print(f\"xmax = {data['xmax']} shape {data['xmax'].shape}\")\n",
    "\n",
    "            # pose from RGB\n",
    "            loss = dsacstar.backward_rgb(\n",
    "                scene_coordinates.cpu(),\n",
    "                scene_coordinates_gradients,\n",
    "                gt_pose, \n",
    "                opt.hypotheses, \n",
    "                opt.threshold,\n",
    "                focal_length, \n",
    "                float(image.size(3) / 2), #principal point assumed in image center\n",
    "                float(image.size(2) / 2),\n",
    "                opt.weightrot,\n",
    "                opt.weighttrans,\n",
    "                opt.softclamp,\n",
    "                opt.inlieralpha,\n",
    "                opt.maxpixelerror,\n",
    "                network.OUTPUT_SUBSAMPLE,\n",
    "                random.randint(0,1000000), #used to initialize random number generator in cpp\n",
    "                data['xmin'].item(),\n",
    "                data['xmax'].item()\n",
    "            )\n",
    "    \n",
    "            \n",
    "            running_loss += loss\n",
    "            torch.autograd.backward((scene_coordinates),(scene_coordinates_gradients.cuda()))\n",
    "            optimizer.step()\n",
    "            if it%opt.print_every==0 and it!=0:\n",
    "                writer.add_scalar('train loss',running_loss/it)\n",
    "                \n",
    "        \n",
    "        writer.add_scalar('per_epoch_training_loss',running_loss/len(trainset_loader),epoch)\n",
    "        \n",
    "\n",
    "        if epoch%opt.save_every==0:\n",
    "            checkpoint_path = os.path.join(checkpoint_folder,f'check_point_epoch_{epoch}.pt')\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': network.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "\n",
    "                }, checkpoint_path\n",
    "            )\n",
    "       \n",
    "        print(f\"loss: {running_loss}\")\n",
    "    \n",
    "    with open(os.path.join(checkpoint_folder,'loss_list.pickle'),'wb') as f:\n",
    "        pickle.dump({'loss_list':loss_list,'per_epoch_loss_list':per_epoch_loss_list}, f)\n",
    "\n",
    "    \n",
    "\n",
    "train(network = network, optimizer=optimizer, iteration=iteration)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
